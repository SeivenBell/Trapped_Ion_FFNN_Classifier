{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"ename":"SyntaxError","evalue":"(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2112286663.py, line 56)","output_type":"error","traceback":["\u001b[1;36m  Cell \u001b[1;32mIn[1], line 56\u001b[1;36m\u001b[0m\n\u001b[1;33m    file_path_pt = 'C:\\Users\\Seiven\\Desktop\\MY_MLmodels\\ions2\\binary\\labels_and_images.pt'\u001b[0m\n\u001b[1;37m                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"]}],"source":["import sys\n","import re\n","import h5py\n","import copy\n","import torch\n","import random\n","import torchvision\n","import numpy as np\n","import numpy as np\n","from torch import nn\n","from torch.optim import Adam\n","from torchinfo import summary\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Subset\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset\n","from torch.utils.data import ConcatDataset\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","\n","#-------------------------------------------------------\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(str(device))\n","file_path = \"C:/Users/Seiven/Desktop/MY_MLmodels/ions2/binary/cropped_ions.h5\"\n","\n","file_path_dark = \"C:/Users/Seiven/Desktop/MY_MLmodels/ions2/binary/dark_ions.h5\"\n","file_path_bright = \"C:/Users/Seiven/Desktop/MY_MLmodels/ions2/binary/bright_ions.h5\"\n","\n","\n","N = 4\n","L_x = 5 \n","L_y = 5\n","N_i = L_x * L_y\n","N_h = 256\n","N_o = 1\n","\n","\n","class IonImagesDataset(Dataset):\n","    def __init__(self, file_path):\n","        loaded_data_dict = torch.load(file_path)\n","\n","        self.images = loaded_data_dict['images']\n","        self.labels = loaded_data_dict['labels']\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_tensor = self.images[idx]  # Add a channel dimension\n","        label_tensor = self.labels[idx] # Repeat the label for each ion position\n","        return image_tensor, label_tensor\n","\n","#writer = SummaryWriter('runs/ion_images_experiment')\n","file_path_pt = r'C:\\Users\\Seiven\\Desktop\\MY_MLmodels\\ions2\\binary\\labels_and_images.pt'\n","halfpi_file_path_pt = r'C:\\Users\\Seiven\\Desktop\\MY_MLmodels\\ions2\\binary\\halfpi.pt'\n","\n","dataset = IonImagesDataset(file_path_pt)\n","halfpi_dataset = IonImagesDataset(file_path_pt)\n","\n","# Split the dataset into training and validation subsets\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","print(f\"Train size: {train_size}, Validation size: {val_size}\")  # Print the sizes of subsets\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print(f\"Train dataset size: {len(train_dataset)}\")  # Print the size of the train_dataset\n","print(f\"Validation dataset size: {len(val_dataset)}\")  # Print the size of the val_dataset\n","\n","# Create DataLoaders for the training and validation datasets\n","batch_size = min(1000, len(train_dataset)) # or choose a smaller value\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n","\n","halfpi_loader = DataLoader(halfpi_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n","\n","\n","class IndexDependentDense(nn.Module):\n","    def __init__(self, N, N_i, N_o, activation=nn.ReLU()):\n","        super().__init__()\n","        \n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        self.activation = activation\n","        self.register_parameter(\n","            \"W\", nn.Parameter(torch.empty(self.N, self.N_i, self.N_o))\n","        )\n","        self.register_parameter(\"b\", nn.Parameter(torch.empty(self.N, self.N_o)))\n","        \n","        self._reset_parameters()\n","        \n","        pass\n","    \n","    def _reset_parameters(self):\n","        nn.init.xavier_uniform_(self.W)\n","        nn.init.zeros_(self.b)\n","\n","    def forward(self,x):\n","        y = torch.einsum(\"nij,...ni->...nj\", self.W, x) + self.b\n","        if self.activation is not None:\n","            return self.activation(y)\n","        else:\n","            return y\n","    pass\n","\n","#---------------------------------------------------------------------------------------------\n","\n","class Encoder(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","        \n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        \n","        self.dense = IndexDependentDense(N, N_i, N_o, activation=nn.ReLU())\n","        pass\n","    \n","    def forward(self, x):\n","        y = self.dense(x)\n","        return y\n","    pass\n","\n","#---------------------------------------------------------------------------------------------\n","\n","class Classifier(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","        \n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        self.dense = IndexDependentDense(N, N_i, N_o, activation=None)\n","        pass\n","    def forward(self, x):\n","        y = self.dense(x)\n","        y = torch.sigmoid(y)  # Apply sigmoid activation here\n","        return y\n","    pass\n","\n","#---------------------------------------------------------------------------------------------\n","\n","class SharedEncoder(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","        \n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        \n","        self.dense = nn.Linear(N_i, N_o)\n","        pass\n","        \n","    def forward(self, x):\n","        y = self.dense(x)\n","        return y\n","    \n","    pass\n","   \n","#---------------------------------------------------------------------------------------------    \n","        \n","class SharedClassifier(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","        \n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        \n","        self.dense = nn.Linear(N_i, N_o)\n","        pass\n","    \n","    def forward(self, x):\n","        y = self.dense(x)\n","        return y\n","    \n","    pass\n","\n","#---------------------------------------------------------------------------------------------\n","\n","\n","class MultiIonReadout(nn.Module):\n","    def __init__(self, encoder, shared_encoder, classifier):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.shared_encoder = shared_encoder\n","        self.classifier = classifier\n","\n","    def forward(self, x):\n","        y = x.reshape(*x.shape[:-2], -1).to(torch.float32)\n","        y1 = self.encoder(y)\n","        y2 = self.shared_encoder(y)\n","        y_concat = torch.cat([y1, y2], dim=-1)\n","        y = self.classifier(y_concat)\n","        return y\n","\n","    def bceloss(self, X, y):\n","        return F.binary_cross_entropy(self(X), y)\n","\n","    @staticmethod\n","    def _accuracy(y_pred, y_true):\n","        mod_y_pred = (y_pred > 0.5).to(torch.float32)\n","        accuracy = (y_true == mod_y_pred).to(dtype=torch.float32).mean()\n","        return accuracy * 100\n","\n","    def accuracy(self, x, y):\n","        return self._accuracy(self(x), y)\n","#---------------------------------------------------------------------------------------------\n","\n","class EnhancedMultiIonReadout(nn.Module):\n","    def __init__(self, mir):\n","        super().__init__()\n","        \n","        self.mir = copy.deepcopy(mir)\n","        \n","        for p in self.mir.parameters():\n","            p.requires_grad_(False)\n","\n","    def forward(self, x):\n","        y = x.reshape(*x.shape[:-2], -1).to(torch.float32)\n","        y = self.mir.encoder(y)\n","        y = self.mir.classifier(y)\n","        return y"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cpu\")\n","\n","encoder = Encoder(N, N_i, N_h)\n","shared_encoder = SharedEncoder(N, N_i, N_h)\n","classifier = Classifier(N, N_h * 2, N_o)\n","model = MultiIonReadout(encoder, shared_encoder, classifier)\n","# enhanced_model = EnhancedMultiIonReadout(model)\n","\n","model = model.to(device)\n","\n","# # Create a SummaryWriter\n","# writer = SummaryWriter('runs/ion_images_experiment')\n","\n","# # Log model architecture (Optional)\n","# images, _ = next(iter(train_loader))\n","# writer.add_graph(model, images)\n","\n","N_epochs = 100\n","lr = 1e-3\n","optimizer = Adam(model.parameters(), lr=lr)\n","schedule_params = {\"factor\": 1}\n","schedule = lr_scheduler.ConstantLR(optimizer, **schedule_params)\n","log_every = 1\n","\n","# Training loop\n","for epoch in range(N_epochs):\n","\n","    total_train_loss = 0\n","    for (inputs, labels) in train_loader:\n","    \n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        loss = model.bceloss(inputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # total_train_loss += loss.item()\n","\n","    # avg_train_loss = total_train_loss / len(train_loader)\n","    \n","    sys.stdout.flush()\n","    # writer.add_scalar('Training Loss', avg_train_loss, epoch)\n","\n","    # Evaluation loop\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_accuracy = 0\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            loss = model.bceloss(inputs, labels)\n","            accuracy = model.accuracy(inputs, labels)\n","            total_loss += loss.item()\n","            total_accuracy += accuracy.item()\n","\n","        avg_loss = total_loss / len(val_loader)\n","        avg_accuracy = total_accuracy / len(val_loader)\n","        # writer.add_scalar('Validation Loss', avg_loss, epoch)\n","        # writer.add_scalar('Validation Accuracy', avg_accuracy, epoch)\n","        \n","    print(\"\\r Epoch {}/{}, Training Loss = {}, Val Loss = {}, Val Acc = {}\".format(epoch+1, N_epochs, loss.item(), avg_loss, avg_accuracy), end=\"\")\n","    \n","# Close the writer\n","# writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from collections import Counter\n","import seaborn as sns\n","\n","preds = []\n","\n","for (inputs, labels) in halfpi_loader:\n","    \n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        preds.append(model.forward(inputs))\n","\n","preds = [b for i in preds for b in i]\n","\n","# Make the tensor values binary for each tensor in the list\n","binary_preds = [(pred > 0.5).float() for pred in preds]\n","\n","#import seaborn as sns\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","# Convert each tensor to a string and count occurrences\n","tensor_str_counts = Counter([str(tensor.tolist()) for tensor in binary_preds])\n","\n","# Prepare data for plotting\n","labels = [label for label in tensor_str_counts.keys()]\n","counts = [count for count in tensor_str_counts.values()]\n","\n","# Sort by counts\n","sorted_labels, sorted_counts = zip(*sorted(zip(labels, counts), key=lambda x: x[1]))\n","\n","# Convert tuples to lists\n","sorted_labels = list(sorted_labels)\n","sorted_counts = list(sorted_counts)\n","\n","# Create the countplot\n","plt.figure(figsize=(15, 8))\n","sns.barplot(x=sorted_labels, y=sorted_counts)\n","\n","plt.title('Count of Each Unique Class in binary_preds')\n","plt.xlabel('Unique Classes')\n","plt.ylabel('Count')\n","plt.xticks(rotation=25)\n","plt.savefig('sorted_results.png')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Trash"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ion_positions=[0, 1, 2, 3]\n","images = []\n","categories = []\n","labels = [\"dark\", \"bright\"]\n","file_paths = [file_path_dark, file_path_bright]\n","\n","for file_path, label in zip(file_paths, labels):\n","    with h5py.File(file_path, \"r\") as f:\n","        print(f\"h5 file has {len(f.keys())} keys.\")  # Print the number of keys\n","#                 print(f\"h5 file has {f.keys()} keys.\") \n","# \n","        # # Get the unique image numbers from the keys\n","        # image_numbers = [int(re.search(r'(\\d+)_ion_0', key).group(1)) for key in f.keys()]\n","\n","        image_number = 0\n","        # while image_number<100:\n","        while True:\n","            try:\n","                image_tensors = []\n","                for ion_position in ion_positions:\n","                    key = f\"{label}_{image_number}_ion_{ion_position}\"\n","                    ion_image = np.array(f[key])  # Load data as a numpy array\n","                    ion_image_tensor = torch.tensor(ion_image, dtype=torch.float32).view(L_x, L_y) -200  # Reshape the tensor\n","                    image_tensors.append(ion_image_tensor)\n","\n","                # Concatenate the image tensors for all ion positions\n","                combined_image_tensor = torch.stack(image_tensors)\n","                images.append(combined_image_tensor[None,...])\n","                categories.append(torch.tensor([0,0,0,0],dtype=torch.float32)[:,None] if label == \"dark\" else torch.tensor([1,1,1,1],dtype=torch.float32)[:,None])\n","\n","                image_number += 1\n","            except:\n","                break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import itertools\n","import random\n","\n","# Function to swap slices based on label values\n","def swap_slices(categories, images):\n","    for i in range(4):  # Loop over each position in the tensor\n","        # Find tensors that have 1 at the i-th position\n","        ones_indices = [idx for idx, cat in enumerate(categories) if cat[i] == 1]\n","        \n","        # Find tensors that have 0 at the i-th position\n","        zeros_indices = [idx for idx, cat in enumerate(categories) if cat[i] == 0]\n","        \n","        # Randomly select half from the ones_indices\n","        ones_to_swap = random.sample(ones_indices, len(ones_indices) // 2)\n","        \n","        # Randomly select the same number from the zeros_indices\n","        zeros_to_swap = random.sample(zeros_indices, len(ones_to_swap))\n","        \n","        # Perform the swap\n","        for one, zero in zip(ones_to_swap, zeros_to_swap):\n","            images[one][0, i], images[zero][0, i] = images[zero][0, i].clone(), images[one][0, i].clone()\n","            \n","            # Also swap the corresponding labels\n","            categories[one][i], categories[zero][i] = categories[zero][i], categories[one][i]\n","\n","swap_slices(categories, images)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["new_categories = []\n","new_images = []\n","remove_count = 10_000\n","for cat, img in zip(categories, images):\n","    if str(cat.tolist()) == '[[0.0], [0.0], [0.0], [0.0]]':\n","        if remove_count > 0:\n","            remove_count -= 1\n","            continue\n","    new_categories.append(cat)\n","    new_images.append(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Counter([str(tensor.tolist()) for tensor in new_categories])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["images = torch.concat(new_images,dim=0)\n","labels = torch.stack(new_categories)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a dictionary to hold both tensors\n","data_dict = {\n","    'labels': labels,\n","    'images': images\n","}\n","\n","# Save the dictionary as a .pt file\n","torch.save(data_dict, 'labels_and_images.pt')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
